{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction and PCA\n",
    "\n",
    "Let's revisit the MNIST digits dataset. \n",
    "\n",
    "Notebook objectives: \n",
    "\n",
    "* Learn sklearn syntax for PCA \n",
    "* Look at an example of using PCA for visualization\n",
    "* Learn how to use a scree plot to explore how many principal components to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 16., 15.,  1.,  0.,  0.],\n",
       "       [ 0.,  1., 15.,  9., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  3., 16.,  1.,  0., 16.,  4.,  0.],\n",
       "       [ 0.,  6., 16.,  0.,  0., 11.,  6.,  0.],\n",
       "       [ 0.,  3., 16.,  1.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 16.,  4.,  3., 15.,  4.,  0.],\n",
       "       [ 0.,  1., 13., 13., 13., 14.,  1.,  0.],\n",
       "       [ 0.,  0.,  4., 13., 14.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what one digit looks like in numbers\n",
    "digits.data[166].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL2UlEQVR4nO3d34tc9RnH8c/HNcFf0ZWYihhxK5aACN0ECZWAbBKVWCW96UUCCpWW9KIVQwuivSn+A7K9KEKIGsEY0Wi0SGsN6CJCq82PtYluLBpW3EbdqMSohQaTpxdzUtK4dc/G8z07O8/7BUNmdmfP88xuPnPOmTlzHkeEAPS2s2a7AQDlEXQgAYIOJEDQgQQIOpAAQQcS6Iqg215j+23b79i+t3Cth21P2t5fss4p9a6w/bLtMdtv2r67cL1zbL9u+42q3v0l61U1+2zvtf186VpVvXHb+2yP2t5VuFa/7e22D1R/w+sL1lpSPaaTl6O2Nzay8IiY1YukPknvSrpK0nxJb0i6pmC9GyQtk7S/pcd3maRl1fUFkv5R+PFZ0gXV9XmSXpP0g8KP8VeSHpf0fEu/03FJl7RU61FJP6uuz5fU31LdPkkfSrqyieV1wxp9uaR3IuJgRByT9ISkH5UqFhGvSPq01PKnqPdBROyprn8uaUzS5QXrRUR8Ud2cV12KHRVle7GkWyVtLlVjtti+UJ0Vw0OSFBHHIuJIS+VXS3o3It5rYmHdEPTLJb1/yu0JFQzCbLI9IGmpOmvZknX6bI9KmpS0MyJK1huWdI+kEwVrnC4kvWh7t+0NBetcJemwpEeqXZPNts8vWO9U6yRta2ph3RB0T/G1njsu1/YFkp6WtDEijpasFRHHI2JQ0mJJy21fW6KO7dskTUbE7hLL/wYrImKZpFsk/cL2DYXqnK3Obt6DEbFU0peSir6GJEm250taK+mpppbZDUGfkHTFKbcXSzo0S70UYXueOiHfGhHPtFW32swckbSmUIkVktbaHldnl2uV7ccK1fqviDhU/TspaYc6u38lTEiaOGWLaLs6wS/tFkl7IuKjphbYDUH/m6Tv2f5u9Uy2TtIfZrmnxti2Ovt4YxHxQAv1Ftnur66fK+lGSQdK1IqI+yJicUQMqPN3eykibi9R6yTb59tecPK6pJslFXkHJSI+lPS+7SXVl1ZLeqtErdOsV4Ob7VJn02RWRcRXtn8p6c/qvNL4cES8Waqe7W2ShiRdYntC0m8j4qFS9dRZ690haV+13yxJv4mIPxaqd5mkR233qfNE/mREtPK2V0sulbSj8/ypsyU9HhEvFKx3l6St1UrooKQ7C9aS7fMk3STp540ut3opH0AP64ZNdwCFEXQgAYIOJEDQgQQIOpBAVwW98OGMs1aLetSb7XpdFXRJbf4yW/3DUY96s1mv24IOoIAiB8zY7umjcC666KIZ/8yxY8c0f/78M6p39dVXz/hnDh8+rEWLFp1RvePHj8/4Zz755BMtXLjwjOrt27dvxj9z4sQJnXXWma2nzuTxzSUR8bUPis36IbBz0dDQUKv1nn322VbrffbZZ63WGxgYaLXekSNtfaS8e7DpDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggVpBb3NkEoDmTRv06iSDv1fnFLTXSFpv+5rSjQFoTp01eqsjkwA0r07Q04xMAnpVnQ+11BqZVH1Qvu3P7AKooU7Qa41MiohNkjZJvf8xVWCuqbPp3tMjk4AMpl2jtz0yCUDzap14opoTVmpWGIDCODIOSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACPTGSqb+/v81yGh8fb7Xeli1bWq3X9u+z7UktbU/aadtUI5lYowMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBOiOZHrY9aXt/Gw0BaF6dNfoWSWsK9wGgoGmDHhGvSPq0hV4AFMI+OpBArfO618HsNaB7NRZ0Zq8B3YtNdyCBOm+vbZP0F0lLbE/Y/mn5tgA0qc6QxfVtNAKgHDbdgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4k0BOz1wYHB9ssp71797Za7+KLL2613pEjR1qtV+L/4DdZuXJlq/VGRkZarcfsNSApgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRQ5+SQV9h+2faY7Tdt391GYwCaU+e87l9J+nVE7LG9QNJu2zsj4q3CvQFoSJ3Zax9ExJ7q+ueSxiRdXroxAM2Z0T667QFJSyW9VqIZAGXUHslk+wJJT0vaGBFHp/g+s9eALlUr6LbnqRPyrRHxzFT3YfYa0L3qvOpuSQ9JGouIB8q3BKBpdfbRV0i6Q9Iq26PV5YeF+wLQoDqz116V9LVT0wCYOzgyDkiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAArU/1NLN2p691ra2Z6G17bnnnmu13sDAQKv1ugFrdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRQ5yyw59h+3fYb1ey1+9toDEBz6hzr/m9JqyLii+r87q/a/lNE/LVwbwAaUucssCHpi+rmvOrCgAZgDqm1j267z/aopElJOyOC2WvAHFIr6BFxPCIGJS2WtNz2taffx/YG27ts72q6SQDfzoxedY+II5JGJK2Z4nubIuK6iLiuod4ANKTOq+6LbPdX18+VdKOkA6UbA9CcOq+6XybpUdt96jwxPBkRz5dtC0CT6rzq/ndJS1voBUAhHBkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBnpi9Njo6OtstFNXf399qvV6f9cbsNQA9iaADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ1A56NcRhr21ODAnMMTNZo98taaxUIwDKqTuSabGkWyVtLtsOgBLqrtGHJd0j6UTBXgAUUmdSy22SJiNi9zT3Y/Ya0KXqrNFXSFpre1zSE5JW2X7s9Dsxew3oXtMGPSLui4jFETEgaZ2klyLi9uKdAWgM76MDCczoVFIRMaLO2GQAcwhrdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCfTE7LW2Z5O1bXBwsNV6bc9eGxoaarXe8PBwq/W6AWt0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJFDrENjqVM+fSzou6StO6QzMLTM51n1lRHxcrBMAxbDpDiRQN+gh6UXbu21vKNkQgObV3XRfERGHbH9H0k7bByLilVPvUD0B8CQAdKFaa/SIOFT9Oylph6TlU9yH2WtAl6ozTfV82wtOXpd0s6T9pRsD0Jw6m+6XStph++T9H4+IF4p2BaBR0wY9Ig5K+n4LvQAohLfXgAQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4k4IhofqF28wv9Bm3PXhsZGWm1Xq9r++/X67PsIsKnf401OpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxKoFXTb/ba32z5ge8z29aUbA9CcugMcfifphYj4se35ks4r2BOAhk0bdNsXSrpB0k8kKSKOSTpWti0ATaqz6X6VpMOSHrG91/bmapDD/7C9wfYu27sa7xLAt1In6GdLWibpwYhYKulLSfeefidGMgHdq07QJyRNRMRr1e3t6gQfwBwxbdAj4kNJ79teUn1ptaS3inYFoFF1X3W/S9LW6hX3g5LuLNcSgKbVCnpEjEpi3xuYozgyDkiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAj0xe61tQ0NDrdYbHh5utR6z0OY2Zq8BSRF0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJTBt020tsj55yOWp7YxvNAWjGtOeMi4i3JQ1Kku0+Sf+UtKNwXwAaNNNN99WS3o2I90o0A6CMmQZ9naRtJRoBUE7toFfndF8r6an/831mrwFdqu4AB0m6RdKeiPhoqm9GxCZJm6Te/5gqMNfMZNN9vdhsB+akWkG3fZ6kmyQ9U7YdACXUHcn0L0kLC/cCoBCOjAMSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIoNXvtsKQz+cz6JZI+bridbqhFPeq1Ve/KiFh0+heLBP1M2d4VEdf1Wi3qUW+267HpDiRA0IEEui3om3q0FvWoN6v1umofHUAZ3bZGB1AAQQcSIOhAAgQdSICgAwn8B0mBnIwRn3czAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take the shading for each pixel and plot it as color\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[166])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 64)\n"
     ]
    }
   ],
   "source": [
    "# Center the data on 0 \n",
    "# We should do this (almost) all of the time so that we don't fit to covariates \n",
    "# that happen to be on larger scales and have more variance\n",
    "\n",
    "X_centered = digits.data - digits.data.mean()\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_centered, y, test_size=0.5,random_state=42)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some PCA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ama</th>\n",
       "      <td>tldr do whatever the fuck you want so youre te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>askreddit</th>\n",
       "      <td>victorias secret was originally supposed to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dankmemes</th>\n",
       "      <td>meme of the month seeding and nominations for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>but i wanted the robot ferret haha suck it you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memes</th>\n",
       "      <td>redditmc is opening staff positions builders h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>am i reading this correctly to conclude that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worldnews</th>\n",
       "      <td>so was there any posts left after the purge ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsb</th>\n",
       "      <td>after  green days in a row  wsb wtf where did ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text\n",
       "ama        tldr do whatever the fuck you want so youre te...\n",
       "askreddit  victorias secret was originally supposed to be...\n",
       "dankmemes  meme of the month seeding and nominations for ...\n",
       "funny      but i wanted the robot ferret haha suck it you...\n",
       "memes      redditmc is opening staff positions builders h...\n",
       "science    am i reading this correctly to conclude that t...\n",
       "worldnews  so was there any posts left after the purge ok...\n",
       "wsb        after  green days in a row  wsb wtf where did ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_pickle('./pickles/data_clean.pickle')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all of the data and plot it on 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "pcafeatures_train = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the PCA results\n",
    "from itertools import cycle\n",
    "\n",
    "def plot_PCA_2D(data, target, target_names):\n",
    "    colors = cycle(['r','g','b','c','m','y','orange','w','aqua','yellow'])\n",
    "    target_ids = range(len(target_names))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i, c, label in zip(target_ids, colors, target_names):\n",
    "        plt.scatter(data[target == i, 0], data[target == i, 1],\n",
    "                   c=c, label=label, edgecolors='gray')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of all the numbers\n",
    "plot_PCA_2D(pcafeatures_train, target=y_train, target_names=digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming our input matrix X for use in classification/clustering \n",
    "\n",
    "Here we did PCA for visualization. But we can take our new N x k matrix (where k = number principal components) as input to regression, classification, clustering, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transf = pca.transform(X_train)\n",
    "print(\"shape of original X_train:\", X_train.shape)\n",
    "print(\"shape of X_train using 2 principal components:\", X_transf.shape, \"\\n\")\n",
    "print(X_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to understand the importance of each variable in each PC, look at the correlations:\n",
    "\n",
    "pd.DataFrame(pca.components_, index = ['PC1','PC2'])\n",
    "\n",
    "# remember, signs don't matter, just direction in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.singular_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing number of components with a scree plot\n",
    "\n",
    "Choosing two or three components makes sense if we're using PCA for visualization. But what if we're trying to do feature extraction and need to use the components as input for our classifcation/clustering task? Then we might use a scree plot to choose the number of components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=15)\n",
    "pca2.fit(X_train)\n",
    "pcafeatures_train2 = pca2.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca2.explained_variance_ratio_)\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('explained variance');\n",
    "plt.title('Scree plot for digits dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca2.explained_variance_ratio_))\n",
    "plt.xlabel('# components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.title('Cumulative explained variance by PCA for digits');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: t-SNE\n",
    "\n",
    "Adapted from the [O-Reilly Media t-SNE tutorial](https://github.com/oreillymedia/t-SNE-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn implements t-SNE.\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.manifold.t_sne import (_joint_probabilities,\n",
    "                                    _kl_divergence)\n",
    "\n",
    "# Import seaborn and matplotlib.patheffects to make nice plots.\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "# Random state.\n",
    "RS = 20200807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first reorder the data points according to the handwritten numbers.\n",
    "X = np.vstack([digits.data[digits.target==i]\n",
    "               for i in range(10)])\n",
    "y = np.hstack([digits.target[digits.target==i]\n",
    "               for i in range(10)])\n",
    "digits_proj = TSNE(random_state=RS).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, colors):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(digits_proj, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Visualized!\n",
    "\n",
    "[How t-SNE runs on the digits dataset](https://github.com/oreillymedia/t-SNE-tutorial/raw/master/images/animation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
