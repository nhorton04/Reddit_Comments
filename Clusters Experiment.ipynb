{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['text', 'matrix', 'shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# standard code block #\n",
    "#######################\n",
    "\n",
    "# see https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%pylab inline\n",
    "\n",
    "# sets backend to render higher res images\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "\n",
    "# uses custom metis style sheet for notebooks\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<link rel=\"stylesheet\" href=\"https://soph.info/metis/nb.css\" type=\"text/css\"/>\"\"\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# spacy.prefer_gpu()\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsb</th>\n",
       "      <th>science</th>\n",
       "      <th>ama</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>funny</th>\n",
       "      <th>dankmemes</th>\n",
       "      <th>memes</th>\n",
       "      <th>nosleep</th>\n",
       "      <th>psychology</th>\n",
       "      <th>politics</th>\n",
       "      <th>cscareerquestions</th>\n",
       "      <th>writingprompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>future apple   share gran kid ask not buy appl...</td>\n",
       "      <td>child motivate achieve maximum reward extent...</td>\n",
       "      <td>tldr fuck want tell people internet lie   funn...</td>\n",
       "      <td>victorias secret originally suppose place man ...</td>\n",
       "      <td>post leave purge ok context   facebook estimat...</td>\n",
       "      <td>want robot ferret haha suck fool get robotic f...</td>\n",
       "      <td>meme month seed nomination july     nomination...</td>\n",
       "      <td>redditmc open staff position builder helper mo...</td>\n",
       "      <td>look like story click   reminder check later g...</td>\n",
       "      <td>decision mental health care canada    study ...</td>\n",
       "      <td>wait hold fucking phone   spend like   minute ...</td>\n",
       "      <td>hi   ve look stable job freelancing rn past ye...</td>\n",
       "      <td>holy mackerel guy spotlight writer writer hack...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    wsb  \\\n",
       "text  future apple   share gran kid ask not buy appl...   \n",
       "\n",
       "                                                science  \\\n",
       "text    child motivate achieve maximum reward extent...   \n",
       "\n",
       "                                                    ama  \\\n",
       "text  tldr fuck want tell people internet lie   funn...   \n",
       "\n",
       "                                              askreddit  \\\n",
       "text  victorias secret originally suppose place man ...   \n",
       "\n",
       "                                              worldnews  \\\n",
       "text  post leave purge ok context   facebook estimat...   \n",
       "\n",
       "                                                  funny  \\\n",
       "text  want robot ferret haha suck fool get robotic f...   \n",
       "\n",
       "                                              dankmemes  \\\n",
       "text  meme month seed nomination july     nomination...   \n",
       "\n",
       "                                                  memes  \\\n",
       "text  redditmc open staff position builder helper mo...   \n",
       "\n",
       "                                                nosleep  \\\n",
       "text  look like story click   reminder check later g...   \n",
       "\n",
       "                                             psychology  \\\n",
       "text    decision mental health care canada    study ...   \n",
       "\n",
       "                                               politics  \\\n",
       "text  wait hold fucking phone   spend like   minute ...   \n",
       "\n",
       "                                      cscareerquestions  \\\n",
       "text  hi   ve look stable job freelancing rn past ye...   \n",
       "\n",
       "                                         writingprompts  \n",
       "text  holy mackerel guy spotlight writer writer hack...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data_df = pd.read_pickle('lemmatized_bigstrings.pickle')\n",
    "wsb = data_df.T['wsb'].tolist()\n",
    "wsb\n",
    "data_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wsb = data_df.text['wsb']\n",
    "# wsb.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "text  1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvn = TfidfVectorizer(ngram_range=(1,1))\n",
    "data_cvn = cvn.fit_transform(data_df)\n",
    "wsb_dtm = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names()).T\n",
    "# wsb.columns = data_df.index\n",
    "wsb_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ama</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>cscareerquestions</th>\n",
       "      <th>dankmemes</th>\n",
       "      <th>funny</th>\n",
       "      <th>memes</th>\n",
       "      <th>nosleep</th>\n",
       "      <th>politics</th>\n",
       "      <th>psychology</th>\n",
       "      <th>science</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>writingprompts</th>\n",
       "      <th>wsb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ama  askreddit  cscareerquestions  dankmemes  funny  memes  nosleep  \\\n",
       "0   0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "1   0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "2   1.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "3   0.0        1.0                0.0        0.0    0.0    0.0      0.0   \n",
       "4   0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "5   0.0        0.0                0.0        0.0    1.0    0.0      0.0   \n",
       "6   0.0        0.0                0.0        1.0    0.0    0.0      0.0   \n",
       "7   0.0        0.0                0.0        0.0    0.0    1.0      0.0   \n",
       "8   0.0        0.0                0.0        0.0    0.0    0.0      1.0   \n",
       "9   0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "10  0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "11  0.0        0.0                1.0        0.0    0.0    0.0      0.0   \n",
       "12  0.0        0.0                0.0        0.0    0.0    0.0      0.0   \n",
       "\n",
       "    politics  psychology  science  worldnews  writingprompts  wsb  \n",
       "0        0.0         0.0      0.0        0.0             0.0  1.0  \n",
       "1        0.0         0.0      1.0        0.0             0.0  0.0  \n",
       "2        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "3        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "4        0.0         0.0      0.0        1.0             0.0  0.0  \n",
       "5        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "6        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "7        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "8        0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "9        0.0         1.0      0.0        0.0             0.0  0.0  \n",
       "10       1.0         0.0      0.0        0.0             0.0  0.0  \n",
       "11       0.0         0.0      0.0        0.0             0.0  0.0  \n",
       "12       0.0         0.0      0.0        0.0             1.0  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "matrix = vec.fit_transform(data_df.T)\n",
    "idf_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_samples=1 should be >= n_clusters=20.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fd31efc38722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Normally people fit the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# But you could fit the idf_df instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# km.fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1033\u001b[0m                                 accept_large_sparse=False)\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;31m# n_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             raise ValueError(f\"n_samples={X.shape[0]} should be >= \"\n\u001b[0m\u001b[1;32m    959\u001b[0m                              f\"n_clusters={self.n_clusters}.\")\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_samples=1 should be >= n_clusters=20."
     ]
    }
   ],
   "source": [
    "# KMeans clustering a kind of clustering.\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "number_of_clusters=20\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "# Normally people fit the matrix\n",
    "km.fit(matrix)\n",
    "# But you could fit the idf_df instead\n",
    "# km.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(wsb_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans = kmeans.predict(wsb_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
    "def display_cluster(X,km=[],num_clusters=0):\n",
    "    color = 'brgcmyk'\n",
    "    alpha = 0.5\n",
    "    s = 20\n",
    "    if num_clusters == 0:\n",
    "        plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
    "    else:\n",
    "        for i in range(num_clusters):\n",
    "            plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i],alpha = alpha,s=s)\n",
    "            plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.linspace(0,2*np.pi,20, endpoint = False)\n",
    "X = np.append([np.cos(angle)],[np.sin(angle)],0).transpose()\n",
    "display_cluster(wsb_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "km = KMeans(n_clusters=num_clusters,random_state=10,n_init=1) # n_init, number of times the K-mean algorithm will run\n",
    "km.fit(data_dtmn)\n",
    "display_cluster(data_dtmn,km,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 7\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(data_dtmn.transpose())\n",
    "display_cluster(data_dtmn.transpose(),km,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
