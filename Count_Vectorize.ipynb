{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "spacy.prefer_gpu()\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsb</th>\n",
       "      <th>science</th>\n",
       "      <th>ama</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>funny</th>\n",
       "      <th>dankmemes</th>\n",
       "      <th>memes</th>\n",
       "      <th>nosleep</th>\n",
       "      <th>psychology</th>\n",
       "      <th>politics</th>\n",
       "      <th>cscareerquestions</th>\n",
       "      <th>writingprompts</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aaaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaaaaaa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aaaaaaaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙄𝙏</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙄𝙏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙏𝙃𝙀</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙏𝙃𝙀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙔𝙀𝙎</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙔𝙀𝙎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝚃𝚑𝚒𝚜</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝚃𝚑𝚒𝚜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111923 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              wsb  science  ama  askreddit  worldnews  funny  dankmemes  \\\n",
       "aa              0       10    0          9          2      0          0   \n",
       "aaa             5        0    0          3          0      0          0   \n",
       "aaaaa           0        0    0          0          0      0          0   \n",
       "aaaaaaaa        0        0    0          1          0      0          0   \n",
       "aaaaaaaaaaaa    0        0    0          1          1      0          0   \n",
       "...           ...      ...  ...        ...        ...    ...        ...   \n",
       "𝙄𝙏              0        0    0          1          0      0          0   \n",
       "𝙏𝙃𝙀             0        0    0          2          0      0          0   \n",
       "𝙔𝙀𝙎             0        0    0          1          0      0          0   \n",
       "𝚃𝚑𝚒𝚜            0        0    0          0          0      0          0   \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎        0        0    0          0          0      0          0   \n",
       "\n",
       "              memes  nosleep  psychology  politics  cscareerquestions  \\\n",
       "aa                0        1           2         2                  0   \n",
       "aaa               0        0           0         2                  0   \n",
       "aaaaa             1        0           0         0                  0   \n",
       "aaaaaaaa          0        0           0         0                  0   \n",
       "aaaaaaaaaaaa      0        0           0         0                  0   \n",
       "...             ...      ...         ...       ...                ...   \n",
       "𝙄𝙏                0        0           0         0                  0   \n",
       "𝙏𝙃𝙀               0        0           0         0                  0   \n",
       "𝙔𝙀𝙎               0        0           0         0                  0   \n",
       "𝚃𝚑𝚒𝚜              1        0           0         0                  0   \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎          1        0           0         0                  0   \n",
       "\n",
       "              writingprompts         index  \n",
       "aa                         0            aa  \n",
       "aaa                        0           aaa  \n",
       "aaaaa                      0         aaaaa  \n",
       "aaaaaaaa                   0      aaaaaaaa  \n",
       "aaaaaaaaaaaa               0  aaaaaaaaaaaa  \n",
       "...                      ...           ...  \n",
       "𝙄𝙏                         0            𝙄𝙏  \n",
       "𝙏𝙃𝙀                        0           𝙏𝙃𝙀  \n",
       "𝙔𝙀𝙎                        0           𝙔𝙀𝙎  \n",
       "𝚃𝚑𝚒𝚜                       0          𝚃𝚑𝚒𝚜  \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎                   0      𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎  \n",
       "\n",
       "[111923 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the document-term matrix\n",
    "\n",
    "data_cv = pd.read_pickle('dtm_cv.pickle')\n",
    "data_cv = data_cv.transpose()\n",
    "data_cv['index'] = data_cv.index\n",
    "# data_cv.transpose()\n",
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsb</th>\n",
       "      <th>science</th>\n",
       "      <th>ama</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>funny</th>\n",
       "      <th>dankmemes</th>\n",
       "      <th>memes</th>\n",
       "      <th>nosleep</th>\n",
       "      <th>psychology</th>\n",
       "      <th>politics</th>\n",
       "      <th>cscareerquestions</th>\n",
       "      <th>writingprompts</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aba</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacavir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abacavir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>aback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abagails</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abagails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙄𝙏</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙄𝙏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙏𝙃𝙀</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙏𝙃𝙀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝙔𝙀𝙎</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝙔𝙀𝙎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝚃𝚑𝚒𝚜</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝚃𝚑𝚒𝚜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111828 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wsb  science  ama  askreddit  worldnews  funny  dankmemes  memes  \\\n",
       "ab          3       29    0          7          0      0          0      0   \n",
       "aba         0        2    0          2          0      0          0      0   \n",
       "abacavir    0        1    0          0          0      0          0      0   \n",
       "aback       0        4    0          2          1      0          0      0   \n",
       "abagails    0        0    0          0          0      0          0      0   \n",
       "...       ...      ...  ...        ...        ...    ...        ...    ...   \n",
       "𝙄𝙏          0        0    0          1          0      0          0      0   \n",
       "𝙏𝙃𝙀         0        0    0          2          0      0          0      0   \n",
       "𝙔𝙀𝙎         0        0    0          1          0      0          0      0   \n",
       "𝚃𝚑𝚒𝚜        0        0    0          0          0      0          0      1   \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎    0        0    0          0          0      0          0      1   \n",
       "\n",
       "          nosleep  psychology  politics  cscareerquestions  writingprompts  \\\n",
       "ab              2           0         3                  2               8   \n",
       "aba             0           0         0                  0               0   \n",
       "abacavir        0           0         0                  0               0   \n",
       "aback           0           0         1                  1               3   \n",
       "abagails        1           0         0                  0               0   \n",
       "...           ...         ...       ...                ...             ...   \n",
       "𝙄𝙏              0           0         0                  0               0   \n",
       "𝙏𝙃𝙀             0           0         0                  0               0   \n",
       "𝙔𝙀𝙎             0           0         0                  0               0   \n",
       "𝚃𝚑𝚒𝚜            0           0         0                  0               0   \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎        0           0         0                  0               0   \n",
       "\n",
       "             index  \n",
       "ab              ab  \n",
       "aba            aba  \n",
       "abacavir  abacavir  \n",
       "aback        aback  \n",
       "abagails  abagails  \n",
       "...            ...  \n",
       "𝙄𝙏              𝙄𝙏  \n",
       "𝙏𝙃𝙀            𝙏𝙃𝙀  \n",
       "𝙔𝙀𝙎            𝙔𝙀𝙎  \n",
       "𝚃𝚑𝚒𝚜          𝚃𝚑𝚒𝚜  \n",
       "𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎  𝚝𝚎𝚖𝚙𝚕𝚊𝚝𝚎  \n",
       "\n",
       "[111828 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in enumerate(data_cv['index']):\n",
    "    candidate = re.match('a{2,}', str(row))\n",
    "    if candidate != None:\n",
    "        data_cv.drop(row, inplace=True)\n",
    "    if row == 'ababababba':\n",
    "        data_cv.drop(row, inplace=True)\n",
    "    if row == 'wa':\n",
    "        data_cv.drop(row, inplace=True)       \n",
    "    if row == 'ha':\n",
    "        data_cv.drop(row, inplace=True)    \n",
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab63687bcb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubreddit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wc' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "for index, subreddit in enumerate(data_cv.columns):\n",
    "    wc.generate(data_clean.text[subreddit])\n",
    "    plt.subplot(4, 3, index + 1)\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(subreddit)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-49cbee1c55fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msparse_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparse2Corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             coo_tocsr(M, N, self.nnz, row, col, self.data,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(data_cv)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{36625: 'future',\n",
       " 4480: 'apple',\n",
       " 88219: 'share',\n",
       " 39193: 'gran',\n",
       " 52974: 'kids',\n",
       " 5381: 'ask',\n",
       " 24704: 'didnt',\n",
       " 12769: 'buy',\n",
       " 110819: 'youll',\n",
       " 3670: 'answer',\n",
       " 10941: 'bought',\n",
       " 19541: 'corn',\n",
       " 49440: 'instead',\n",
       " 93270: 'stare',\n",
       " 590: 'account',\n",
       " 109645: 'wow',\n",
       " 69066: 'options',\n",
       " 84988: 'safe',\n",
       " 37008: 'gang',\n",
       " 82062: 'responded',\n",
       " 29189: 'email',\n",
       " 97932: 'thanks',\n",
       " 82275: 'retard',\n",
       " 91140: 'social',\n",
       " 49660: 'interaction',\n",
       " 94705: 'sub',\n",
       " 100893: 'trending',\n",
       " 99009: 'tickers',\n",
       " 87572: 'sentiments',\n",
       " 84773: 'rwallstreetbets',\n",
       " 22339: 'day',\n",
       " 6120: 'august',\n",
       " 99008: 'tickercompanymentionsbulls',\n",
       " 8080: 'bearspricechangepe',\n",
       " 101487: 'tslatesla',\n",
       " 92765: 'spyexchange',\n",
       " 100349: 'traded',\n",
       " 90572: 'slvexchange',\n",
       " 69: 'aaplapple',\n",
       " 19572: 'cornexchange',\n",
       " 83326: 'rktrocket',\n",
       " 17889: 'companies',\n",
       " 63308: 'msftmicrosoft',\n",
       " 2911: 'amdadvanced',\n",
       " 60730: 'micro',\n",
       " 7810: 'bathe',\n",
       " 10361: 'boeing',\n",
       " 32982: 'fbfacebook',\n",
       " 77298: 'prplpurple',\n",
       " 49201: 'innovation',\n",
       " 78163: 'qqqexchange',\n",
       " 65065: 'netcloudflare',\n",
       " 21110: 'cscocisco',\n",
       " 96326: 'systems',\n",
       " 67478: 'nvdanvidia',\n",
       " 99010: 'tickerstriketypeexpiration',\n",
       " 87569: 'sentiment',\n",
       " 87571: 'sentimentcomments',\n",
       " 22222: 'data',\n",
       " 69848: 'overall',\n",
       " 58667: 'market',\n",
       " 12253: 'bullish',\n",
       " 17726: 'comments',\n",
       " 86595: 'searched',\n",
       " 65278: 'newly',\n",
       " 65058: 'net',\n",
       " 21109: 'csco',\n",
       " 67477: 'nvda',\n",
       " 105780: 'view',\n",
       " 84170: 'rreddittickers',\n",
       " 66963: 'notice',\n",
       " 30476: 'error',\n",
       " 78420: 'questions',\n",
       " 81620: 'reply',\n",
       " 74902: 'post',\n",
       " 60384: 'message',\n",
       " 104630: 'usmallstreetgains',\n",
       " 33761: 'financial',\n",
       " 77241: 'provided',\n",
       " 44932: 'httpsfinvizcom',\n",
       " 110402: 'year',\n",
       " 68334: 'old',\n",
       " 36629: 'futures',\n",
       " 100359: 'trader',\n",
       " 108450: 'whos',\n",
       " 5403: 'asleep',\n",
       " 24062: 'desk',\n",
       " 110424: 'years',\n",
       " 109859: 'wtf',\n",
       " 9891: 'blew',\n",
       " 99604: 'today',\n",
       " 33184: 'feels',\n",
       " 6973: 'bad',\n",
       " 56871: 'lost',\n",
       " 43624: 'hopping',\n",
       " 100361: 'trades',\n",
       " 70062: 'overnight',\n",
       " 37044: 'gap',\n",
       " 5796: 'ath',\n",
       " 86765: 'secured',\n",
       " 104688: 'usually',\n",
       " 7273: 'balls',\n",
       " 99330: 'tingle',\n",
       " 89385: 'significant',\n",
       " 77670: 'pullback',\n",
       " 12263: 'bulls',\n",
       " 109837: 'wsb',\n",
       " 22143: 'dark',\n",
       " 108640: 'wild',\n",
       " 99823: 'tonight',\n",
       " 41727: 'heard',\n",
       " 37798: 'getting',\n",
       " 94441: 'strippers',\n",
       " 106618: 'wait',\n",
       " 71550: 'pay',\n",
       " 86774: 'security',\n",
       " 55520: 'life',\n",
       " 56238: 'lmao',\n",
       " 101289: 'trump',\n",
       " 23317: 'delete',\n",
       " 80192: 'record',\n",
       " 42538: 'high',\n",
       " 101831: 'tweet',\n",
       " 75816: 'prepping',\n",
       " 93864: 'stimulus',\n",
       " 71292: 'passing',\n",
       " 4424: 'apparently',\n",
       " 83857: 'roommate',\n",
       " 106847: 'wants',\n",
       " 15132: 'cheaper',\n",
       " 4289: 'apartment',\n",
       " 35215: 'forgot',\n",
       " 87806: 'set',\n",
       " 85128: 'salary',\n",
       " 6347: 'automatically',\n",
       " 108993: 'withdraw',\n",
       " 96946: 'taxes',\n",
       " 92294: 'spent',\n",
       " 65421: 'nice',\n",
       " 4848: 'area',\n",
       " 76150: 'pricepoint',\n",
       " 17074: 'cockroaches',\n",
       " 70349: 'owns',\n",
       " 88229: 'shares',\n",
       " 97735: 'tesla',\n",
       " 80762: 'refuses',\n",
       " 87287: 'sell',\n",
       " 22674: 'debts',\n",
       " 80220: 'recover',\n",
       " 14033: 'cash',\n",
       " 85642: 'savings',\n",
       " 18764: 'considering',\n",
       " 56180: 'living',\n",
       " 62628: 'months',\n",
       " 85624: 'save',\n",
       " 62420: 'money',\n",
       " 98476: 'thinks',\n",
       " 73617: 'planet',\n",
       " 34108: 'fitness',\n",
       " 94873: 'subscription',\n",
       " 104547: 'use',\n",
       " 7822: 'bathrooms',\n",
       " 13074: 'calculated',\n",
       " 109338: 'words',\n",
       " 29587: 'encouragement',\n",
       " 60904: 'middle',\n",
       " 86005: 'school',\n",
       " 94565: 'students',\n",
       " 68683: 'online',\n",
       " 16375: 'classroom',\n",
       " 78397: 'question',\n",
       " 96539: 'taking',\n",
       " 11335: 'break',\n",
       " 47560: 'ill',\n",
       " 57351: 'lurk',\n",
       " 90591: 'small',\n",
       " 71167: 'participate',\n",
       " 100371: 'trading',\n",
       " 71987: 'penny',\n",
       " 93958: 'stocks',\n",
       " 79711: 'real',\n",
       " 40250: 'guys',\n",
       " 43590: 'hope',\n",
       " 82874: 'rich',\n",
       " 101478: 'tsla',\n",
       " 110568: 'yes',\n",
       " 99783: 'tomorrow',\n",
       " 57355: 'lurking',\n",
       " 107096: 'watch',\n",
       " 89273: 'sidelines',\n",
       " 77985: 'puts',\n",
       " 37453: 'general',\n",
       " 88147: 'shambled',\n",
       " 13168: 'calls',\n",
       " 23831: 'depression',\n",
       " 46453: 'huge',\n",
       " 49938: 'interview',\n",
       " 107525: 'week',\n",
       " 36186: 'fucking',\n",
       " 41387: 'hate',\n",
       " 51655: 'job',\n",
       " 83424: 'rn',\n",
       " 9110: 'big',\n",
       " 18901: 'consultant',\n",
       " 95066: 'sucksfuck',\n",
       " 11631: 'bro',\n",
       " 4245: 'anyways',\n",
       " 65242: 'new',\n",
       " 19328: 'cool',\n",
       " 78947: 'raise',\n",
       " 11758: 'bros',\n",
       " 62617: 'month',\n",
       " 51786: 'joke',\n",
       " 53101: 'kinda',\n",
       " 108946: 'wish',\n",
       " 83551: 'robinhood',\n",
       " 37250: 'gave',\n",
       " 69058: 'option',\n",
       " 90974: 'sniper',\n",
       " 10108: 'blow',\n",
       " 11187: 'brains',\n",
       " 56836: 'lose',\n",
       " 25022: 'dingus',\n",
       " 100161: 'touch',\n",
       " 109798: 'wrong',\n",
       " 27473: 'dte',\n",
       " 92761: 'spy',\n",
       " 33028: 'fds',\n",
       " 76072: 'pretty',\n",
       " 6552: 'awesome',\n",
       " 24559: 'diarrhea',\n",
       " 19103: 'contracts',\n",
       " 109585: 'worth',\n",
       " 110608: 'yesterday',\n",
       " 98354: 'theyre',\n",
       " 13245: 'came',\n",
       " 52522: 'karma',\n",
       " 74304: 'political',\n",
       " 11946: 'bs',\n",
       " 81640: 'reporter',\n",
       " 63018: 'motherfucker',\n",
       " 101448: 'trying',\n",
       " 84458: 'ruin',\n",
       " 6720: 'baba',\n",
       " 5391: 'asking',\n",
       " 15528: 'china',\n",
       " 36146: 'fuck',\n",
       " 2734: 'alternate',\n",
       " 109476: 'world',\n",
       " 4256: 'aoc',\n",
       " 68696: 'onlyfans',\n",
       " 38051: 'girlfriends',\n",
       " 89777: 'sister',\n",
       " 37887: 'giant',\n",
       " 99472: 'titties',\n",
       " 38685: 'gone',\n",
       " 43871: 'hours',\n",
       " 108053: 'whats',\n",
       " 38342: 'glued',\n",
       " 41455: 'havent',\n",
       " 33695: 'filled',\n",
       " 9481: 'bird',\n",
       " 33150: 'feeder',\n",
       " 9494: 'birds',\n",
       " 56694: 'looking',\n",
       " 76412: 'problem',\n",
       " 94641: 'stupid',\n",
       " 90570: 'slv',\n",
       " 38695: 'gonna',\n",
       " 16459: 'clear',\n",
       " 94865: 'subs',\n",
       " 33767: 'financially',\n",
       " 3589: 'announces',\n",
       " 52784: 'kernel',\n",
       " 92490: 'split',\n",
       " 56512: 'lol',\n",
       " 33163: 'feel',\n",
       " 26842: 'dow',\n",
       " 68875: 'open',\n",
       " 56681: 'look',\n",
       " 97412: 'tell',\n",
       " 39227: 'grandkids',\n",
       " 95251: 'summer',\n",
       " 56851: 'losing',\n",
       " 88692: 'shitposting',\n",
       " 98422: 'things',\n",
       " 81300: 'remember',\n",
       " 8792: 'best',\n",
       " 107844: 'went',\n",
       " 6761: 'baby',\n",
       " 93666: 'steps',\n",
       " 11070: 'boys',\n",
       " 12787: 'buys',\n",
       " 99370: 'tip',\n",
       " 87309: 'sells',\n",
       " 25073: 'dip',\n",
       " 94012: 'stonkfucius',\n",
       " 59095: 'math',\n",
       " 107552: 'weeks',\n",
       " 101703: 'turn',\n",
       " 88624: 'shit',\n",
       " 38962: 'gotta',\n",
       " 93319: 'start',\n",
       " 7664: 'bartending',\n",
       " 93492: 'stay',\n",
       " 101634: 'tuned',\n",
       " 50713: 'itd',\n",
       " 967: 'add',\n",
       " 9136: 'biggest',\n",
       " 108850: 'winner',\n",
       " 56843: 'loser',\n",
       " 96358: 'tab',\n",
       " 63202: 'moves',\n",
       " 98732: 'threads',\n",
       " 108444: 'whored',\n",
       " 2910: 'amd',\n",
       " 99475: 'titty',\n",
       " 38947: 'goth',\n",
       " 38045: 'girlfriend',\n",
       " 893: 'actually',\n",
       " 95898: 'swallows',\n",
       " 24598: 'dick',\n",
       " 68905: 'opens',\n",
       " 99517: 'tm',\n",
       " 12607: 'bust',\n",
       " 32885: 'fattest',\n",
       " 67446: 'nuts',\n",
       " 109580: 'worst',\n",
       " 27204: 'drilling',\n",
       " 88540: 'shilling',\n",
       " 55174: 'lesson',\n",
       " 26837: 'dover',\n",
       " 43198: 'hold',\n",
       " 35191: 'forget',\n",
       " 109130: 'woke',\n",
       " 36818: 'gains',\n",
       " 80463: 'reduced',\n",
       " 56853: 'loss',\n",
       " 64796: 'need',\n",
       " 94037: 'stop',\n",
       " 12779: 'buying',\n",
       " 84602: 'running',\n",
       " 82513: 'reverses',\n",
       " 93330: 'starting',\n",
       " 47255: 'id',\n",
       " 8881: 'better',\n",
       " 99295: 'timing',\n",
       " 71328: 'past',\n",
       " 80213: 'recouped',\n",
       " 56857: 'losses',\n",
       " 58183: 'man',\n",
       " 22582: 'dear',\n",
       " 38490: 'god',\n",
       " 73945: 'pls',\n",
       " 77712: 'pump',\n",
       " 99529: 'tmr',\n",
       " 68625: 'ones',\n",
       " 68953: 'opinions',\n",
       " 59156: 'matter',\n",
       " 98726: 'thread',\n",
       " 27634: 'dumbass',\n",
       " 38112: 'gives',\n",
       " 74343: 'politics',\n",
       " 56066: 'literally',\n",
       " 47348: 'idiocracy',\n",
       " 83168: 'rip',\n",
       " 104491: 'usa',\n",
       " 36430: 'fund',\n",
       " 61171: 'millenials',\n",
       " 13732: 'care',\n",
       " 33008: 'fd',\n",
       " 43203: 'holders',\n",
       " 12121: 'bugatti',\n",
       " 72178: 'percocets',\n",
       " 62312: 'molly',\n",
       " 81503: 'rep',\n",
       " 33110: 'fed',\n",
       " 15065: 'chase',\n",
       " 93848: 'stimmy',\n",
       " 15163: 'check',\n",
       " 9566: 'bitch',\n",
       " 41977: 'held',\n",
       " 84601: 'runnin',\n",
       " 1830: 'ah',\n",
       " 68276: 'ok',\n",
       " 105984: 'virus',\n",
       " 34658: 'flu',\n",
       " 86614: 'season',\n",
       " 19616: 'corona',\n",
       " 42955: 'hit',\n",
       " 36161: 'fucked',\n",
       " 95659: 'sure',\n",
       " 110237: 'yall',\n",
       " 10623: 'book',\n",
       " 80141: 'recommendations',\n",
       " 32519: 'fan',\n",
       " 64473: 'nations',\n",
       " 32287: 'fail',\n",
       " 22178: 'daron',\n",
       " 664: 'acemoglu',\n",
       " 104233: 'upheaval',\n",
       " 19417: 'cope',\n",
       " 20726: 'crisis',\n",
       " 14886: 'change',\n",
       " 51159: 'jared',\n",
       " 24536: 'diamond',\n",
       " 29426: 'empire',\n",
       " 23482: 'democracy',\n",
       " 89538: 'simon',\n",
       " 80950: 'reidhenry',\n",
       " 7730: 'basically',\n",
       " 65920: 'non',\n",
       " 23490: 'democratic',\n",
       " 74017: 'plutocracy',\n",
       " 104328: 'upside',\n",
       " 94016: 'stonks',\n",
       " 55198: 'let',\n",
       " 58689: 'markets',\n",
       " 13776: 'cares',\n",
       " 28346: 'economy',\n",
       " 20039: 'country',\n",
       " 12499: 'burns',\n",
       " 22460: 'dd',\n",
       " 75974: 'press',\n",
       " 99718: 'tolerable',\n",
       " 16279: 'clang',\n",
       " 7974: 'bc',\n",
       " 58008: 'making',\n",
       " 105323: 'vegetables',\n",
       " 37604: 'genuinely',\n",
       " 42733: 'hilarious',\n",
       " 17651: 'coming',\n",
       " 91616: 'soon',\n",
       " 22558: 'deal',\n",
       " 96598: 'talks',\n",
       " 62662: 'mood',\n",
       " 99059: 'tied',\n",
       " 93937: 'stock',\n",
       " 15063: 'charts',\n",
       " 42055: 'help',\n",
       " 63306: 'msft',\n",
       " 76143: 'price',\n",
       " 63188: 'movement',\n",
       " 72200: 'perfect',\n",
       " 81680: 'representation',\n",
       " 17903: 'company',\n",
       " 10802: 'boring',\n",
       " 103252: 'uneventful',\n",
       " 91390: 'solid',\n",
       " 30024: 'entire',\n",
       " 25922: 'districts',\n",
       " 103568: 'universities',\n",
       " 89152: 'shut',\n",
       " 89363: 'sign',\n",
       " 43302: 'holy',\n",
       " 79751: 'realized',\n",
       " 52402: 'kamalas',\n",
       " 109915: 'wwe',\n",
       " 52397: 'kamala',\n",
       " 41272: 'harris',\n",
       " 24727: 'died',\n",
       " 61265: 'mind',\n",
       " 10128: 'blown',\n",
       " 89793: 'sit',\n",
       " 43311: 'home',\n",
       " 7707: 'basement',\n",
       " 18178: 'computer',\n",
       " 11153: 'brain',\n",
       " 93339: 'starts',\n",
       " 109004: 'wither',\n",
       " 6537: 'away',\n",
       " 56001: 'liquidating',\n",
       " 5544: 'assets',\n",
       " 15174: 'checking',\n",
       " 83259: 'ritz',\n",
       " 13841: 'carlton',\n",
       " 86462: 'scuffling',\n",
       " 94324: 'streets',\n",
       " 40604: 'half',\n",
       " 28210: 'eaten',\n",
       " 57523: 'mac',\n",
       " 19273: 'convinced',\n",
       " 75299: 'ppl',\n",
       " 83154: 'rinvesting',\n",
       " 18783: 'consistent',\n",
       " 96075: 'swings',\n",
       " 31031: 'everyday',\n",
       " 1838: 'ahahahaa',\n",
       " 57993: 'makers',\n",
       " 27632: 'dumb',\n",
       " 108570: 'wife',\n",
       " 87901: 'sex',\n",
       " 351: 'absolutely',\n",
       " 26427: 'dominated',\n",
       " 31446: 'exhilarating',\n",
       " 68196: 'oh',\n",
       " 85505: 'sashimi',\n",
       " 82101: 'rest',\n",
       " 74779: 'portion',\n",
       " 101581: 'tuition',\n",
       " 82957: 'riding',\n",
       " 52943: 'kid',\n",
       " 104554: 'used',\n",
       " 10070: 'bloomberg',\n",
       " 16933: 'cnbc',\n",
       " 79750: 'realize',\n",
       " 1265: 'adults',\n",
       " 43540: 'hooked',\n",
       " 985: 'addictive',\n",
       " 83218: 'risking',\n",
       " 61206: 'millions',\n",
       " 56899: 'lotto',\n",
       " 99012: 'ticket',\n",
       " 15471: 'children',\n",
       " 17583: 'come',\n",
       " 34644: 'flowers',\n",
       " 37916: 'gift',\n",
       " 28430: 'edit',\n",
       " 59266: 'maybe',\n",
       " 83522: 'robbed',\n",
       " 92008: 'spanish',\n",
       " 77644: 'puerto',\n",
       " 82865: 'rican',\n",
       " 40232: 'guy',\n",
       " 56256: 'lmfao',\n",
       " 67566: 'oan',\n",
       " 3879: 'antifacom',\n",
       " 69207: 'organization',\n",
       " 74618: 'poors',\n",
       " 64912: 'neighborhoods',\n",
       " 102275: 'ugh',\n",
       " 43201: 'holder',\n",
       " 102196: 'ucpttonystark',\n",
       " 102010: 'type',\n",
       " 27545: 'dude',\n",
       " 28225: 'eats',\n",
       " 91981: 'spaghetti',\n",
       " 59296: 'mayonnaise',\n",
       " 107568: 'weep',\n",
       " 6269: 'autists',\n",
       " 75176: 'pouring',\n",
       " 89739: 'sir',\n",
       " 32402: 'falling',\n",
       " 85060: 'said',\n",
       " 87297: 'selling',\n",
       " 18569: 'congress',\n",
       " 104134: 'unwilling',\n",
       " 64888: 'negotiate',\n",
       " 1001: 'additional',\n",
       " 60050: 'members',\n",
       " 106407: 'vshape',\n",
       " 80226: 'recovery',\n",
       " 103631: 'unlikely',\n",
       " 56397: 'lockdowns',\n",
       " 106966: 'warranted',\n",
       " 19152: 'control',\n",
       " 54268: 'lapse',\n",
       " 34042: 'fiscal',\n",
       " 54635: 'lead',\n",
       " 27288: 'drop',\n",
       " 18915: 'consumer',\n",
       " 92285: 'spending',\n",
       " 26756: 'doubledip',\n",
       " 80029: 'recession',\n",
       " 31551: 'expect',\n",
       " 49370: 'insolvencies',\n",
       " 83196: 'rise',\n",
       " 32392: 'fall',\n",
       " 33172: 'feeling',\n",
       " 21611: 'cute',\n",
       " 54371: 'later',\n",
       " 15589: 'chipotle',\n",
       " 64819: 'needs',\n",
       " 27308: 'dropping',\n",
       " 39195: 'grand',\n",
       " 12513: 'burrito',\n",
       " 90442: 'slob',\n",
       " 88717: 'shitting',\n",
       " 16115: 'cisco',\n",
       " 23122: 'definitely',\n",
       " 85626: 'saved',\n",
       " 74772: 'portfolio',\n",
       " 84460: 'ruined',\n",
       " 73550: 'place',\n",
       " 72876: 'phone',\n",
       " 25893: 'distracted',\n",
       " 81302: 'remembered',\n",
       " 43205: 'holding',\n",
       " 68: 'aapl',\n",
       " 86705: 'seconds',\n",
       " 16681: 'clock',\n",
       " 69152: 'order',\n",
       " 107060: 'wasnt',\n",
       " 75404: 'pray',\n",
       " 51948: 'jpow',\n",
       " 43215: 'holds',\n",
       " 43610: 'hoping',\n",
       " 31478: 'exit',\n",
       " 42987: 'hits',\n",
       " 101726: 'turns',\n",
       " 80287: 'red',\n",
       " 59182: 'mattress',\n",
       " 94083: 'stores',\n",
       " 97836: 'texas',\n",
       " 42246: 'heres',\n",
       " 54728: 'learned',\n",
       " 95366: 'super',\n",
       " 94072: 'store',\n",
       " 13936: 'carry',\n",
       " 77856: 'purple',\n",
       " 31606: 'expensive',\n",
       " 50726: 'items',\n",
       " 18762: 'considered',\n",
       " 60879: 'mid',\n",
       " 55252: 'level',\n",
       " 91361: 'sold',\n",
       " 24099: 'despite',\n",
       " 41470: 'having',\n",
       " 109321: 'word',\n",
       " 63151: 'mouth',\n",
       " 82397: 'return',\n",
       " 74271: 'policy',\n",
       " 108515: 'wide',\n",
       " 82403: 'returns',\n",
       " 88370: 'sheets',\n",
       " 82142: 'restocking',\n",
       " 106879: 'warehouse',\n",
       " 9129: 'bigger',\n",
       " 31562: 'expected',\n",
       " 102035: 'typically',\n",
       " 82140: 'restock',\n",
       " 25316: 'disclaimer',\n",
       " 26514: 'donny',\n",
       " 26336: 'doing',\n",
       " 15062: 'charting',\n",
       " 97179: 'technical',\n",
       " 3194: 'analysis',\n",
       " 75976: 'presser',\n",
       " 40835: 'hand',\n",
       " 107033: 'washing',\n",
       " 32181: 'facilities',\n",
       " 59563: 'mean',\n",
       " 89697: 'sink',\n",
       " 24630: 'dicks',\n",
       " 32359: 'fake',\n",
       " 19917: 'coughing',\n",
       " 29610: 'end',\n",
       " 76257: 'print',\n",
       " 107642: 'welcome',\n",
       " 81635: 'report',\n",
       " 34910: 'fomo',\n",
       " 98408: 'thing',\n",
       " 94231: 'strat',\n",
       " 65579: 'nikola',\n",
       " 42345: 'hertz',\n",
       " 53537: 'kodak',\n",
       " 60292: 'merging',\n",
       " 35237: 'form',\n",
       " 53552: 'kohertzola',\n",
       " 92141: 'specializing',\n",
       " 27706: 'dumps',\n",
       " 50776: 'itll',\n",
       " 53100: 'kind',\n",
       " 6019: 'attract',\n",
       " 87583: 'separate',\n",
       " 92152: 'species',\n",
       " 82290: 'retards',\n",
       " 25981: 'diversified',\n",
       " 76568: 'products',\n",
       " 52951: 'kidding',\n",
       " 8122: 'beautiful',\n",
       " 55210: 'lets',\n",
       " 33853: 'finish',\n",
       " 94469: 'strong',\n",
       " 82278: 'retarded',\n",
       " 97845: 'text',\n",
       " 43404: 'homies',\n",
       " 62858: 'morning',\n",
       " 90322: 'sleepy',\n",
       " 41582: 'head',\n",
       " 61499: 'minutes',\n",
       " 58936: 'massacred',\n",
       " 11041: 'boy',\n",
       " 17356: 'collapses',\n",
       " 56279: 'load',\n",
       " 89484: 'silver',\n",
       " 33547: 'fickle',\n",
       " 82934: 'ride',\n",
       " 11783: 'brothers',\n",
       " 88399: 'shell',\n",
       " 49321: 'insider',\n",
       " 48880: 'info',\n",
       " 62191: 'mods',\n",
       " 85663: 'saw',\n",
       " 35453: 'fox',\n",
       " 65292: 'news',\n",
       " 56142: 'live',\n",
       " 94291: 'stream',\n",
       " 56940: 'love',\n",
       " 33253: 'fellow',\n",
       " 32123: 'facebook',\n",
       " 39747: 'group',\n",
       " 38608: 'gold',\n",
       " 91818: 'sounds',\n",
       " 94564: 'student',\n",
       " 38116: 'giving',\n",
       " 16334: 'class',\n",
       " 75893: 'presentation',\n",
       " 34592: 'florida',\n",
       " 67348: 'numbers',\n",
       " 22377: 'days',\n",
       " 80634: 'referred',\n",
       " 56540: 'lolol',\n",
       " 75579: 'predictions',\n",
       " 32621: 'far',\n",
       " 40475: 'haha',\n",
       " 5386: 'asked',\n",
       " 29403: 'empathy',\n",
       " 22963: 'deep',\n",
       " 50779: 'itm',\n",
       " 18016: 'competitor',\n",
       " 57995: 'makes',\n",
       " 50053: 'introduce',\n",
       " 73343: 'pinky',\n",
       " 110517: 'yell',\n",
       " 13410: 'candles',\n",
       " 75655: 'prefers',\n",
       " 70731: 'pandemic',\n",
       " 10790: 'boredom',\n",
       " 1424: 'af',\n",
       " 64753: 'neck',\n",
       " 31724: 'explore',\n",
       " 80317: 'reddit',\n",
       " 69755: 'outside',\n",
       " 37267: 'gay',\n",
       " 81642: 'reporters',\n",
       " 101045: 'trillion',\n",
       " 11820: 'browsed',\n",
       " 83896: 'roptions',\n",
       " 96574: 'talk',\n",
       " 97147: 'tech',\n",
       " 57920: 'mainly',\n",
       " 2863: 'amazon',\n",
       " 48318: 'include',\n",
       " 1477: 'afford',\n",
       " 38200: 'gld',\n",
       " 19089: 'contract',\n",
       " 31667: 'expires',\n",
       " 51453: 'jesus',\n",
       " 15798: 'christ',\n",
       " 5465: 'ass',\n",
       " 65248: 'newbie',\n",
       " 91370: 'soldiers',\n",
       " 5790: 'ate',\n",
       " 96913: 'taught',\n",
       " 78300: 'quarter',\n",
       " 10676: 'boomer',\n",
       " 90871: 'snail',\n",
       " 61492: 'minute',\n",
       " 53376: 'knew',\n",
       " 104096: 'unusual',\n",
       " 106701: 'wales',\n",
       " 34885: 'follow',\n",
       " 101915: 'twitter',\n",
       " 70542: 'paid',\n",
       " 25354: 'discord',\n",
       " 48863: 'influence',\n",
       " 21505: 'currently',\n",
       " 109199: 'wonder',\n",
       " 47263: 'idea',\n",
       " 36930: 'gambled',\n",
       " 35519: 'frame',\n",
       " 56117: 'little',\n",
       " 26510: 'donnie',\n",
       " 100880: 'tremendous',\n",
       " 39797: 'growth',\n",
       " 96963: 'taxing',\n",
       " 103560: 'universe',\n",
       " 84622: 'runs',\n",
       " 88826: 'shop',\n",
       " 94430: 'strip',\n",
       " 58117: 'mall',\n",
       " 13138: 'called',\n",
       " 105425: 'ventilator',\n",
       " 53155: 'kings',\n",
       " 11223: 'brand',\n",
       " 54100: 'lamborghini',\n",
       " 8703: 'ber',\n",
       " 54054: 'laid',\n",
       " 21604: 'cut',\n",
       " 41569: 'hd',\n",
       " 83889: 'rope',\n",
       " 74544: 'poof',\n",
       " 15805: 'christian',\n",
       " 7205: 'bale',\n",
       " 73786: 'playing',\n",
       " 27410: 'drums',\n",
       " 36183: 'fuckin',\n",
       " 76269: 'prints',\n",
       " 4881: 'arent',\n",
       " 34551: 'flooding',\n",
       " 26378: 'dollars',\n",
       " 20531: 'create',\n",
       " 48848: 'inflation',\n",
       " 12038: 'bucks',\n",
       " 5560: 'assholes',\n",
       " 82983: 'rigged',\n",
       " 36939: 'game',\n",
       " 12268: 'bullshit',\n",
       " 36219: 'fuckshit',\n",
       " 99710: 'told',\n",
       " 71038: 'parents',\n",
       " 37541: 'genius',\n",
       " 93983: 'stole',\n",
       " 54356: 'late',\n",
       " 48023: 'important',\n",
       " 58265: 'mandatory',\n",
       " 93146: 'stalled',\n",
       " 68870: 'opec',\n",
       " 69662: 'outlook',\n",
       " 39596: 'grim',\n",
       " 58931: 'mass',\n",
       " 31081: 'evictions',\n",
       " 22667: 'debt',\n",
       " 63124: 'mounting',\n",
       " 97564: 'tensions',\n",
       " 47857: 'imo',\n",
       " 1162: 'admit',\n",
       " 83324: 'rkt',\n",
       " 30727: 'etf',\n",
       " 100332: 'tracks',\n",
       " 110967: 'yugioh',\n",
       " 74229: 'pokémon',\n",
       " 13727: 'cards',\n",
       " 14300: 'cause',\n",
       " 17785: 'commodity',\n",
       " 30171: 'eow',\n",
       " 3808: 'anticipated',\n",
       " 38065: 'girls',\n",
       " 68092: 'officially',\n",
       " 38124: 'gl',\n",
       " 101014: 'tries',\n",
       " 4689: 'aquire',\n",
       " 99123: 'tiktok',\n",
       " 41033: 'happen',\n",
       " 41837: 'heavy',\n",
       " 60456: 'metal',\n",
       " 30163: 'eom',\n",
       " 2016: 'airline',\n",
       " 76260: 'printer',\n",
       " 33092: 'february',\n",
       " 25103: 'dips',\n",
       " 6445: 'averaging',\n",
       " 70443: 'pace',\n",
       " 83698: 'roi',\n",
       " 22749: 'december',\n",
       " 84929: 'sacrificed',\n",
       " 75483: 'precious',\n",
       " 60471: 'metals',\n",
       " 56798: 'lord',\n",
       " 8967: 'bezos',\n",
       " 74030: 'plz',\n",
       " 9882: 'bless',\n",
       " 3146: 'amzn',\n",
       " 106680: 'wake',\n",
       " 34321: 'flat',\n",
       " 90491: 'slow',\n",
       " 9864: 'bleed',\n",
       " 90293: 'sleep',\n",
       " 93114: 'staircases',\n",
       " 30959: 'event',\n",
       " 32197: 'fact',\n",
       " 85828: 'scared',\n",
       " 109038: 'witness',\n",
       " 104370: 'upvoted',\n",
       " 27209: 'drink',\n",
       " 65721: 'nkla',\n",
       " 29048: 'eligible',\n",
       " 56576: 'long',\n",
       " 39464: 'green',\n",
       " 109209: 'wondering',\n",
       " 35491: 'fractional',\n",
       " 28183: 'easy',\n",
       " 63597: 'multiplied',\n",
       " 111163: 'zero',\n",
       " 88196: 'shape',\n",
       " 54773: 'leave',\n",
       " 109761: 'write',\n",
       " 77723: 'pumping',\n",
       " 11999: 'bubble',\n",
       " 12530: 'bursts',\n",
       " 28333: 'economic',\n",
       " 20446: 'crashes',\n",
       " 11837: 'brrrrrrr',\n",
       " 43036: 'hmm',\n",
       " 55040: 'lemme',\n",
       " 106761: 'wallstreetbets',\n",
       " 14993: 'charge',\n",
       " 53015: 'kill',\n",
       " 50579: 'isnt',\n",
       " 11578: 'bring',\n",
       " 21974: 'dame',\n",
       " 65508: 'night',\n",
       " 46476: 'huh',\n",
       " 61765: 'miss',\n",
       " 17588: 'comedian',\n",
       " 75925: 'president',\n",
       " 9069: 'biden',\n",
       " 108867: 'wins',\n",
       " 21634: 'cuts',\n",
       " 18412: 'conference',\n",
       " 27005: 'dragging',\n",
       " 94054: 'stopped',\n",
       " 37141: 'gas',\n",
       " 93431: 'station',\n",
       " 70462: 'pack',\n",
       " 56565: 'lone',\n",
       " 93253: 'star',\n",
       " 96605: 'tallbois',\n",
       " 98790: 'threw',\n",
       " 20089: 'couple',\n",
       " 35751: 'freezer',\n",
       " 9562: 'bit',\n",
       " 107109: 'watching',\n",
       " 2945: 'america',\n",
       " 88661: 'shithole',\n",
       " 76384: 'probably',\n",
       " 1956: 'aint',\n",
       " 41043: 'happening',\n",
       " 110522: 'yellow',\n",
       " 95280: 'sun',\n",
       " 27162: 'dress',\n",
       " 26245: 'does',\n",
       " 77669: 'pull',\n",
       " 100347: 'trade',\n",
       " 52841: 'keynesian',\n",
       " 55608: 'lifetime',\n",
       " 99208: 'timeline',\n",
       " 92380: 'spilt',\n",
       " 26986: 'dr',\n",
       " 72111: 'pepper',\n",
       " 13644: 'car',\n",
       " 1747: 'ago',\n",
       " 12726: 'buttons',\n",
       " 93774: 'sticky',\n",
       " 71851: 'peeves',\n",
       " 77168: 'protip',\n",
       " 28074: 'earnings',\n",
       " 92260: 'spell',\n",
       " 3171: 'anal',\n",
       " 61: 'aal',\n",
       " 41726: 'hear',\n",
       " 9235: 'billion',\n",
       " 90656: 'smartphones',\n",
       " 38278: 'globe',\n",
       " 38801: 'google',\n",
       " 91959: 'spacex',\n",
       " 54455: 'launching',\n",
       " 49820: 'internet',\n",
       " 85540: 'satellites',\n",
       " 77240: 'provide',\n",
       " 35661: 'freecheap',\n",
       " 20029: 'countries',\n",
       " 11703: 'brokerage',\n",
       " 4405: 'app',\n",
       " 49415: 'installed',\n",
       " 90631: 'smart',\n",
       " 38264: 'global',\n",
       " 80112: 'recognition',\n",
       " 62678: 'moon',\n",
       " 21983: 'damn',\n",
       " 83508: 'roaring',\n",
       " 58955: 'massive',\n",
       " 29124: 'elon',\n",
       " 59612: 'meant',\n",
       " 56996: 'low',\n",
       " 34973: 'fool',\n",
       " 26454: 'don',\n",
       " 33745: 'finally',\n",
       " 22776: 'decided',\n",
       " 15153: 'cheating',\n",
       " 59165: 'matters',\n",
       " 92101: 'speak',\n",
       " 29818: 'english',\n",
       " 36936: 'gambling',\n",
       " 8490: 'believe',\n",
       " 98663: 'thought',\n",
       " 51796: 'jokes',\n",
       " 98463: 'thinking',\n",
       " 46761: 'husk',\n",
       " 34419: 'flesh',\n",
       " 71394: 'pathetic',\n",
       " 104369: 'upvote',\n",
       " 17709: 'comment',\n",
       " 97923: 'thank',\n",
       " 76623: 'profit',\n",
       " 16723: 'close',\n",
       " 2306: 'algos',\n",
       " 60383: 'mess',\n",
       " 7013: 'badly',\n",
       " ...}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pickle\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())\n",
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:21:13: using symmetric alpha at 0.5\n",
      "INFO - 17:21:13: using symmetric eta at 0.5\n",
      "INFO - 17:21:13: using serial LDA version on this node\n",
      "INFO - 17:21:13: running online (multi-pass) LDA training, 2 topics, 10 passes over the supplied corpus of 111923 documents, updating model once every 2000 documents, evaluating perplexity every 20000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "INFO - 17:21:13: PROGRESS: pass 0, at document #2000/111923\n",
      "INFO - 17:21:13: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:13: topic #0 (0.500): 0.373*\"aaaaaaaa\" + 0.178*\"aaa\" + 0.107*\"aaaaaaaaaaaaaaaall\" + 0.101*\"aaaaaaaaaaaaarrrrggg\" + 0.061*\"aaaaaaaaaaaa\" + 0.046*\"aaaaaaaaah\" + 0.030*\"aa\" + 0.016*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.013*\"aaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:13: topic #1 (0.500): 0.320*\"aaa\" + 0.238*\"aaaaaaaa\" + 0.147*\"aaaaaaaaaaaaaaaall\" + 0.061*\"aaaaaaaaaaaaarrrrggg\" + 0.057*\"aaaaaaaaah\" + 0.055*\"aa\" + 0.052*\"aaaaaaaaaaaa\" + 0.014*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:13: topic diff=4.472569, rho=1.000000\n",
      "INFO - 17:21:13: PROGRESS: pass 0, at document #4000/111923\n",
      "INFO - 17:21:14: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:14: topic #0 (0.500): 0.391*\"aaaaaaaa\" + 0.138*\"aaa\" + 0.098*\"aaaaaaaaaaaaarrrrggg\" + 0.090*\"aaaaaaaaaaaaaaaall\" + 0.064*\"aaaaaaaaaaaa\" + 0.052*\"aaaaaaaaah\" + 0.027*\"aa\" + 0.023*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.019*\"aaaaaaaaaaaaaaaa\" + 0.011*\"aaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:14: topic #1 (0.500): 0.336*\"aaa\" + 0.203*\"aaaaaaaa\" + 0.158*\"aaaaaaaaaaaaaaaall\" + 0.062*\"aaaaaaaaaaaa\" + 0.059*\"aa\" + 0.055*\"aaaaaaaaah\" + 0.047*\"aaaaaaaaaaaaarrrrggg\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.011*\"aaaaaaaaaaaaaaaa\" + 0.011*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:14: topic diff=0.396472, rho=0.707107\n",
      "INFO - 17:21:14: PROGRESS: pass 0, at document #6000/111923\n",
      "INFO - 17:21:14: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:14: topic #0 (0.500): 0.397*\"aaaaaaaa\" + 0.147*\"aaaaaaaaaaaaarrrrggg\" + 0.116*\"aaa\" + 0.079*\"aaaaaaaaaaaaaaaall\" + 0.069*\"aaaaaaaaah\" + 0.049*\"aaaaaaaaaaaa\" + 0.028*\"aa\" + 0.023*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.015*\"aaaaaaaaaaaaaaaa\" + 0.010*\"aaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:14: topic #1 (0.500): 0.354*\"aaa\" + 0.174*\"aaaaaaaa\" + 0.164*\"aaaaaaaaaaaaaaaall\" + 0.065*\"aaaaaaaaaaaa\" + 0.059*\"aa\" + 0.055*\"aaaaaaaaah\" + 0.052*\"aaaaaaaaaaaaarrrrggg\" + 0.013*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.011*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.010*\"aaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:14: topic diff=0.160330, rho=0.577350\n",
      "INFO - 17:21:14: PROGRESS: pass 0, at document #8000/111923\n",
      "INFO - 17:21:15: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:15: topic #0 (0.500): 0.431*\"aaaaaaaa\" + 0.125*\"aaaaaaaaaaaaarrrrggg\" + 0.100*\"aaa\" + 0.085*\"aaaaaaaaah\" + 0.072*\"aaaaaaaaaaaaaaaall\" + 0.039*\"aaaaaaaaaaaa\" + 0.032*\"aa\" + 0.024*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.016*\"aaaaaaaaaaaaaaaa\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic #1 (0.500): 0.358*\"aaa\" + 0.170*\"aaaaaaaaaaaaaaaall\" + 0.163*\"aaaaaaaa\" + 0.076*\"aa\" + 0.064*\"aaaaaaaaaaaa\" + 0.048*\"aaaaaaaaah\" + 0.046*\"aaaaaaaaaaaaarrrrggg\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.010*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic diff=0.088607, rho=0.500000\n",
      "INFO - 17:21:15: PROGRESS: pass 0, at document #10000/111923\n",
      "INFO - 17:21:15: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:15: topic #0 (0.500): 0.457*\"aaaaaaaa\" + 0.108*\"aaaaaaaaaaaaarrrrggg\" + 0.092*\"aaaaaaaaah\" + 0.091*\"aaa\" + 0.069*\"aaaaaaaaaaaaaaaall\" + 0.035*\"aaaaaaaaaaaa\" + 0.033*\"aa\" + 0.025*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.018*\"aaaaaaaaaaaaaaaa\" + 0.011*\"aaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic #1 (0.500): 0.336*\"aaa\" + 0.214*\"aaaaaaaaaaaaaaaall\" + 0.154*\"aaaaaaaa\" + 0.080*\"aa\" + 0.062*\"aaaaaaaaaaaa\" + 0.041*\"aaaaaaaaaaaaarrrrggg\" + 0.040*\"aaaaaaaaah\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.010*\"aaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic diff=0.106057, rho=0.447214\n",
      "INFO - 17:21:15: PROGRESS: pass 0, at document #12000/111923\n",
      "INFO - 17:21:15: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:15: topic #0 (0.500): 0.471*\"aaaaaaaa\" + 0.113*\"aaaaaaaaah\" + 0.093*\"aaaaaaaaaaaaarrrrggg\" + 0.083*\"aaa\" + 0.061*\"aaaaaaaaaaaaaaaall\" + 0.037*\"aa\" + 0.032*\"aaaaaaaaaaaa\" + 0.024*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.017*\"aaaaaaaaaaaaaaaa\" + 0.013*\"aaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic #1 (0.500): 0.340*\"aaa\" + 0.198*\"aaaaaaaaaaaaaaaall\" + 0.149*\"aaaaaaaa\" + 0.098*\"aa\" + 0.063*\"aaaaaaaaaaaa\" + 0.041*\"aaaaaaaaah\" + 0.036*\"aaaaaaaaaaaaarrrrggg\" + 0.012*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:15: topic diff=0.095829, rho=0.408248\n",
      "INFO - 17:21:15: PROGRESS: pass 0, at document #14000/111923\n",
      "INFO - 17:21:16: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:16: topic #0 (0.500): 0.475*\"aaaaaaaa\" + 0.109*\"aaaaaaaaah\" + 0.099*\"aaaaaaaaaaaaarrrrggg\" + 0.081*\"aaa\" + 0.058*\"aaaaaaaaaaaaaaaall\" + 0.033*\"aa\" + 0.032*\"aaaaaaaaaaaa\" + 0.025*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.020*\"aaaaaaaaaaaaaaaa\" + 0.013*\"aaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:16: topic #1 (0.500): 0.324*\"aaa\" + 0.197*\"aaaaaaaaaaaaaaaall\" + 0.141*\"aaaaaaaa\" + 0.136*\"aa\" + 0.064*\"aaaaaaaaaaaa\" + 0.037*\"aaaaaaaaaaaaarrrrggg\" + 0.034*\"aaaaaaaaah\" + 0.010*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.008*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.008*\"aaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:16: topic diff=0.042818, rho=0.377964\n",
      "INFO - 17:21:16: PROGRESS: pass 0, at document #16000/111923\n",
      "INFO - 17:21:16: merging changes from 2000 documents into a model of 111923 documents\n",
      "INFO - 17:21:16: topic #0 (0.500): 0.480*\"aaaaaaaa\" + 0.108*\"aaaaaaaaah\" + 0.093*\"aaaaaaaaaaaaarrrrggg\" + 0.081*\"aaa\" + 0.057*\"aaaaaaaaaaaaaaaall\" + 0.030*\"aaaaaaaaaaaa\" + 0.030*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.028*\"aa\" + 0.022*\"aaaaaaaaaaaaaaaa\" + 0.013*\"aaaaaaaaaaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:16: topic #1 (0.500): 0.356*\"aaa\" + 0.186*\"aaaaaaaaaaaaaaaall\" + 0.135*\"aaaaaaaa\" + 0.111*\"aa\" + 0.080*\"aaaaaaaaaaaa\" + 0.037*\"aaaaaaaaaaaaarrrrggg\" + 0.030*\"aaaaaaaaah\" + 0.010*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.009*\"aaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + 0.007*\"aaaaaaaaaaaaaaaa\"\n",
      "INFO - 17:21:16: topic diff=0.036630, rho=0.353553\n",
      "INFO - 17:21:16: PROGRESS: pass 0, at document #18000/111923\n",
      "INFO - 17:21:16: merging changes from 2000 documents into a model of 111923 documents\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-9972f888f4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# we need to specify two other parameters as well - the number of topics and the number of passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    992\u001b[0m                         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reached the end of input; now waiting for all remaining jobs to finish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mother\u001b[0m  \u001b[0;31m# frees up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_mstep\u001b[0;34m(self, rho, other, extra_pass)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0mcurrent_Elogbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_Elogbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_Elogbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_Elogbeta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mPosterior\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-c8b5da857916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'individual_lemmatized.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(vectorizer.get_feature_names())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(X.toarray())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "with open('individual_lemmatized.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "vectorizer = CountVectorizer(input='individual_lemmatized.pickle')\n",
    "X = vectorizer.fit_transform(data.' '.join(values())\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
